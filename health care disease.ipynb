#import dependiencies
import pandas as pd
import numpy as np
from xgboost import XGBClassifier
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')
mydata= pd.read_csv("parkinsons.csv")

df = pd.read_csv("parkinsons.csv")
df.head()
df.isnull().values.any()
df['status'].value_counts()

percent_has_disease= 147 /(147+ 48) *100
percent_didnt_have_disease = 48 /(147 + 48)*100
print("if i guess the individual did not have Parkinsons disease, it would be correct",percent_didnt_have_disease)

print("if i guess the individual that has Parkinsons disease, it would be correct",percent_has_disease)


sns.countplot(df['status'])
#create the feature of data
X = df.drop(['name'],1)
X = np.array(X.drop(['status'],1))
#crate the target data
y=np.array(df['status'])

x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2)

sc = MinMaxScaler(feature_range=(0,1))
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

#createthe XBGClassifier
model = XGBClassifier().fit(x_train,y_train)

#preidictions
preidiction = model.predict(x_test)
preidiction

#get the accuracy , precision, pridictions ,  f1-score
print(classification_report(y_test,preidiction))



